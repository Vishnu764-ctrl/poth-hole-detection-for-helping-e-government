{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPB5ifyC3VE1ZBx0+k8VAra"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3m0X4zvc8i7","executionInfo":{"status":"ok","timestamp":1744219595260,"user_tz":-330,"elapsed":2174942,"user":{"displayName":"POOVARASAN E 2022-2026","userId":"16042538231657499030"}},"outputId":"75fbaaac-81b1-48f3-c1f4-2664cd395f6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 4s/step - accuracy: 0.4799 - loss: 0.7146 - val_accuracy: 0.4306 - val_loss: 0.6955\n","Epoch 2/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - accuracy: 0.4775 - loss: 0.7089 - val_accuracy: 0.4444 - val_loss: 0.6978\n","Epoch 3/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 4s/step - accuracy: 0.5179 - loss: 0.7071 - val_accuracy: 0.5694 - val_loss: 0.6853\n","Epoch 4/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.4790 - loss: 0.7041 - val_accuracy: 0.4444 - val_loss: 0.6870\n","Epoch 5/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.5149 - loss: 0.6968 - val_accuracy: 0.4444 - val_loss: 0.7006\n","Epoch 6/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.5135 - loss: 0.7080 - val_accuracy: 0.4444 - val_loss: 0.6927\n","Epoch 7/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5397 - loss: 0.6903 - val_accuracy: 0.5556 - val_loss: 0.6888\n","Epoch 8/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.4825 - loss: 0.7068 - val_accuracy: 0.4444 - val_loss: 0.6941\n","Epoch 9/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5222 - loss: 0.6985 - val_accuracy: 0.5556 - val_loss: 0.6851\n","Epoch 10/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.4917 - loss: 0.7002 - val_accuracy: 0.4444 - val_loss: 0.6903\n","Epoch 11/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.5061 - loss: 0.6944 - val_accuracy: 0.4444 - val_loss: 0.6812\n","Epoch 12/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.4842 - loss: 0.7016 - val_accuracy: 0.4444 - val_loss: 0.7013\n","Epoch 13/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5206 - loss: 0.7044 - val_accuracy: 0.5556 - val_loss: 0.6937\n","Epoch 14/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5001 - loss: 0.7008 - val_accuracy: 0.5833 - val_loss: 0.6754\n","Epoch 15/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5014 - loss: 0.7007 - val_accuracy: 0.4444 - val_loss: 0.6966\n","Epoch 16/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.5159 - loss: 0.6906 - val_accuracy: 0.5972 - val_loss: 0.6812\n","Epoch 17/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5109 - loss: 0.6966 - val_accuracy: 0.4444 - val_loss: 0.6938\n","Epoch 18/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.4915 - loss: 0.6885 - val_accuracy: 0.5833 - val_loss: 0.6875\n","Epoch 19/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5438 - loss: 0.6903 - val_accuracy: 0.4444 - val_loss: 0.6927\n","Epoch 20/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.4863 - loss: 0.7102 - val_accuracy: 0.5556 - val_loss: 0.6837\n","Epoch 21/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.4851 - loss: 0.6873 - val_accuracy: 0.4444 - val_loss: 0.6938\n","Epoch 22/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.5072 - loss: 0.6912 - val_accuracy: 0.4444 - val_loss: 0.6890\n","Epoch 23/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.5419 - loss: 0.6948 - val_accuracy: 0.5694 - val_loss: 0.6910\n","Epoch 24/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.4972 - loss: 0.6982 - val_accuracy: 0.4444 - val_loss: 0.6826\n","Epoch 25/25\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.5540 - loss: 0.6757 - val_accuracy: 0.5556 - val_loss: 0.7008\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.8613\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["loss: 0.8613\n","compile_metrics: 0.5000\n","Saving model weights and configuration file\n","Saved model to disk\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","       Plain       0.50      1.00      0.67         8\n","     Pothole       0.00      0.00      0.00         8\n","\n","    accuracy                           0.50        16\n","   macro avg       0.25      0.50      0.33        16\n","weighted avg       0.25      0.50      0.33        16\n","\n","F1 Score (binary): 0.0\n","\n","Confusion Matrix:\n","[[8 0]\n"," [8 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["from google.colab import drive\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.utils import shuffle\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Image size\n","size = 100\n","\n","# Load images\n","def load_images_from_folder(folder_path, size):\n","    image_paths = [os.path.join(folder_path, img)\n","                   for img in os.listdir(folder_path)\n","                   if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","    images = [cv2.resize(cv2.imread(path), (size, size)) for path in image_paths if cv2.imread(path) is not None]\n","    return np.array(images)\n","\n","# Load datasets\n","pothole_train = load_images_from_folder(\"/content/drive/MyDrive/Dataset/train/Pothole\", size)\n","plain_train = load_images_from_folder(\"/content/drive/MyDrive/Dataset/train/Plain\", size)\n","pothole_test = load_images_from_folder(\"/content/drive/MyDrive/Dataset/test/Pothole\", size)\n","plain_test = load_images_from_folder(\"/content/drive/MyDrive/Dataset/test/Plain\", size)\n","\n","# Combine data\n","X_train = np.concatenate((pothole_train, plain_train))\n","X_test = np.concatenate((pothole_test, plain_test))\n","y_train = np.concatenate((np.ones(len(pothole_train), dtype=int), np.zeros(len(plain_train), dtype=int)))\n","y_test = np.concatenate((np.ones(len(pothole_test), dtype=int), np.zeros(len(plain_test), dtype=int)))\n","\n","# Shuffle\n","X_train, y_train = shuffle(X_train, y_train, random_state=42)\n","X_test, y_test = shuffle(X_test, y_test, random_state=42)\n","\n","# Normalize images\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# One-hot encode labels\n","y_train = to_categorical(y_train, num_classes=2)\n","y_test = to_categorical(y_test, num_classes=2)\n","\n","# Image augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    brightness_range=[0.7, 1.3],\n","    fill_mode='nearest',\n","    validation_split=0.1  # 10% validation split\n",")\n","\n","# Data generators\n","train_generator = datagen.flow(X_train, y_train, batch_size=32, subset='training')\n","val_generator = datagen.flow(X_train, y_train, batch_size=32, subset='validation')\n","\n","# Define model using VGG16\n","def kerasModelVGG16(size=100):\n","    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n","    model = Sequential()\n","    model.add(base_model)\n","    model.add(GlobalAveragePooling2D())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.1))\n","    model.add(Dense(2, activation='softmax'))\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    return model\n","\n","# Compile model\n","model = kerasModelVGG16(size)\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","history = model.fit(train_generator, validation_data=val_generator, epochs=25)\n","\n","# Evaluate on test data\n","metrics = model.evaluate(X_test, y_test)\n","for name, value in zip(model.metrics_names, metrics):\n","    print(f\"{name}: {value:.4f}\")\n","\n","# Save model\n","print(\"Saving model weights and configuration file\")\n","model.save('sample_vgg16_augmented.h5')\n","model_json = model.to_json()\n","with open(\"sample_vgg16_augmented.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","model.save_weights(\"sample_vgg16_augmented.weights.h5\")\n","print(\"Saved model to disk\")\n","\n","# Predict\n","y_pred_probs = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","y_true_classes = np.argmax(y_test, axis=1)\n","\n","# Evaluation metrics\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true_classes, y_pred_classes, target_names=[\"Plain\", \"Pothole\"]))\n","\n","f1 = f1_score(y_true_classes, y_pred_classes)\n","print(\"F1 Score (binary):\", f1)\n","\n","cm = confusion_matrix(y_true_classes, y_pred_classes)\n","print(\"\\nConfusion Matrix:\")\n","print(cm)\n"]}]}